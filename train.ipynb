{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-30T23:36:53.707861Z",
     "iopub.status.busy": "2024-10-30T23:36:53.707084Z",
     "iopub.status.idle": "2024-10-30T23:38:43.835518Z",
     "shell.execute_reply": "2024-10-30T23:38:43.834232Z",
     "shell.execute_reply.started": "2024-10-30T23:36:53.707813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.4.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.45.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.66.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.20.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "Collecting fuzzy-match\n",
      "  Downloading fuzzy_match-0.0.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading fuzzy_match-0.0.1-py3-none-any.whl (5.4 kB)\n",
      "Installing collected packages: fuzzy-match\n",
      "Successfully installed fuzzy-match-0.0.1\n",
      "Found existing installation: tensorflow 2.16.1\n",
      "Uninstalling tensorflow-2.16.1:\n",
      "  Successfully uninstalled tensorflow-2.16.1\n",
      "Collecting tensorflow-cpu\n",
      "  Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.62.2)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-cpu)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-cpu)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-cpu)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (0.37.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow-cpu) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow-cpu) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow-cpu) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow-cpu) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-cpu) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n",
      "Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.0/230.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, keras, tensorflow-cpu\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.3.2\n",
      "    Uninstalling ml-dtypes-0.3.2:\n",
      "      Successfully uninstalled ml-dtypes-0.3.2\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.3.3\n",
      "    Uninstalling keras-3.3.3:\n",
      "      Successfully uninstalled keras-3.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-cloud 0.1.16 requires tensorflow<3.0,>=1.15.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-3.6.0 ml-dtypes-0.4.1 tensorboard-2.18.0 tensorflow-cpu-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge\n",
    "!pip install bert-score\n",
    "!pip install fuzzy-match\n",
    "!pip uninstall -y tensorflow\n",
    "!pip install tensorflow-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T00:27:55.014333Z",
     "iopub.status.busy": "2024-10-31T00:27:55.013520Z",
     "iopub.status.idle": "2024-10-31T00:27:58.496518Z",
     "shell.execute_reply": "2024-10-31T00:27:58.495395Z",
     "shell.execute_reply.started": "2024-10-31T00:27:55.014286Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'EEG-to-Text-Decoding'...\n",
      "remote: Enumerating objects: 67, done.\u001b[K\n",
      "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
      "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
      "remote: Total 67 (delta 15), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (67/67), 5.73 MiB | 4.41 MiB/s, done.\n",
      "Resolving deltas: 100% (15/15), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/omniaEjust/EEG-to-Text-Decoding.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T00:28:02.121643Z",
     "iopub.status.busy": "2024-10-31T00:28:02.120739Z",
     "iopub.status.idle": "2024-10-31T00:28:02.127802Z",
     "shell.execute_reply": "2024-10-31T00:28:02.126986Z",
     "shell.execute_reply.started": "2024-10-31T00:28:02.121596Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/EEG-to-Text-Decoding\n"
     ]
    }
   ],
   "source": [
    "%cd EEG-to-Text-Decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T00:28:31.689661Z",
     "iopub.status.busy": "2024-10-31T00:28:31.688702Z",
     "iopub.status.idle": "2024-10-31T00:31:37.332211Z",
     "shell.execute_reply": "2024-10-31T00:31:37.330976Z",
     "shell.execute_reply.started": "2024-10-31T00:28:31.689602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/EEG-to-Text-Decoding\n",
      "/kaggle/working/EEG-to-Text-Decoding/config.py\n",
      "/kaggle/working/EEG-to-Text-Decoding/model_decoding_raw.py\n",
      "/kaggle/working/EEG-to-Text-Decoding/data_raw.py\n",
      "/kaggle/lib/kagglegym\n",
      "/kaggle/lib\n",
      "/opt/conda/lib/python310.zip\n",
      "/opt/conda/lib/python3.10\n",
      "/opt/conda/lib/python3.10/lib-dynload\n",
      "/root/.local/lib/python3.10/site-packages\n",
      "/opt/conda/lib/python3.10/site-packages\n",
      "/root/src/BigQuery_Helper\n",
      "[INFO]using model: BrainTranslator\n",
      "[INFO]using use_random_init: False\n",
      "![Debug]using ALL\n",
      "[INFO]eeg type GD\n",
      "[INFO]using bands ['_t1', '_t2', '_a1', '_a2', '_b1', '_b2', '_g1', '_g2']\n",
      "[INFO]using device cuda:0\n",
      "\n",
      "\n",
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "train divider = 320\n",
      "dev divider = 360\n",
      "[INFO]initializing a train set...\n",
      "error in raw eeg\n",
      "insulting\n",
      "The stupidest, most insulting movie of 2002's first quarter.\n",
      "\n",
      "++ adding task to dataset, now we have: 3609\n",
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "train divider = 320\n",
      "dev divider = 360\n",
      "[INFO]initializing a dev set...\n",
      "++ adding task to dataset, now we have: 467\n",
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "train divider = 320\n",
      "dev divider = 360\n",
      "[INFO]initializing a test set...\n",
      "++ adding task to dataset, now we have: 456\n",
      "[INFO]train_set size:  3609\n",
      "[INFO]dev_set size:  467\n",
      "[INFO]test_set size:  456\n",
      "=== start Step1 training ... ===\n",
      "\n",
      " require_grad layers:\n",
      "  pos_embedding\n",
      "  feature_embedded.lstm.weight_ih_l0\n",
      "  feature_embedded.lstm.weight_hh_l0\n",
      "  feature_embedded.lstm.bias_ih_l0\n",
      "  feature_embedded.lstm.bias_hh_l0\n",
      "  feature_embedded.lstm.weight_ih_l0_reverse\n",
      "  feature_embedded.lstm.weight_hh_l0_reverse\n",
      "  feature_embedded.lstm.bias_ih_l0_reverse\n",
      "  feature_embedded.lstm.bias_hh_l0_reverse\n",
      "  feature_embedded.lstm.weight_ih_l1\n",
      "  feature_embedded.lstm.weight_hh_l1\n",
      "  feature_embedded.lstm.bias_ih_l1\n",
      "  feature_embedded.lstm.bias_hh_l1\n",
      "  feature_embedded.lstm.weight_ih_l1_reverse\n",
      "  feature_embedded.lstm.weight_hh_l1_reverse\n",
      "  feature_embedded.lstm.bias_ih_l1_reverse\n",
      "  feature_embedded.lstm.bias_hh_l1_reverse\n",
      "  fc.projection.weight\n",
      "  fc.projection.bias\n",
      "  fc.fc.weight\n",
      "  fc.fc.bias\n",
      "  conv1d_point.weight\n",
      "  conv1d_point.bias\n",
      "  encoder_layer.self_attn.in_proj_weight\n",
      "  encoder_layer.self_attn.in_proj_bias\n",
      "  encoder_layer.self_attn.out_proj.weight\n",
      "  encoder_layer.self_attn.out_proj.bias\n",
      "  encoder_layer.linear1.weight\n",
      "  encoder_layer.linear1.bias\n",
      "  encoder_layer.linear2.weight\n",
      "  encoder_layer.linear2.bias\n",
      "  encoder_layer.norm1.weight\n",
      "  encoder_layer.norm1.bias\n",
      "  encoder_layer.norm2.weight\n",
      "  encoder_layer.norm2.bias\n",
      "  encoder.layers.0.self_attn.in_proj_weight\n",
      "  encoder.layers.0.self_attn.in_proj_bias\n",
      "  encoder.layers.0.self_attn.out_proj.weight\n",
      "  encoder.layers.0.self_attn.out_proj.bias\n",
      "  encoder.layers.0.linear1.weight\n",
      "  encoder.layers.0.linear1.bias\n",
      "  encoder.layers.0.linear2.weight\n",
      "  encoder.layers.0.linear2.bias\n",
      "  encoder.layers.0.norm1.weight\n",
      "  encoder.layers.0.norm1.bias\n",
      "  encoder.layers.0.norm2.weight\n",
      "  encoder.layers.0.norm2.bias\n",
      "  encoder.layers.1.self_attn.in_proj_weight\n",
      "  encoder.layers.1.self_attn.in_proj_bias\n",
      "  encoder.layers.1.self_attn.out_proj.weight\n",
      "  encoder.layers.1.self_attn.out_proj.bias\n",
      "  encoder.layers.1.linear1.weight\n",
      "  encoder.layers.1.linear1.bias\n",
      "  encoder.layers.1.linear2.weight\n",
      "  encoder.layers.1.linear2.bias\n",
      "  encoder.layers.1.norm1.weight\n",
      "  encoder.layers.1.norm1.bias\n",
      "  encoder.layers.1.norm2.weight\n",
      "  encoder.layers.1.norm2.bias\n",
      "  encoder.layers.2.self_attn.in_proj_weight\n",
      "  encoder.layers.2.self_attn.in_proj_bias\n",
      "  encoder.layers.2.self_attn.out_proj.weight\n",
      "  encoder.layers.2.self_attn.out_proj.bias\n",
      "  encoder.layers.2.linear1.weight\n",
      "  encoder.layers.2.linear1.bias\n",
      "  encoder.layers.2.linear2.weight\n",
      "  encoder.layers.2.linear2.bias\n",
      "  encoder.layers.2.norm1.weight\n",
      "  encoder.layers.2.norm1.bias\n",
      "  encoder.layers.2.norm2.weight\n",
      "  encoder.layers.2.norm2.bias\n",
      "  encoder.layers.3.self_attn.in_proj_weight\n",
      "  encoder.layers.3.self_attn.in_proj_bias\n",
      "  encoder.layers.3.self_attn.out_proj.weight\n",
      "  encoder.layers.3.self_attn.out_proj.bias\n",
      "  encoder.layers.3.linear1.weight\n",
      "  encoder.layers.3.linear1.bias\n",
      "  encoder.layers.3.linear2.weight\n",
      "  encoder.layers.3.linear2.bias\n",
      "  encoder.layers.3.norm1.weight\n",
      "  encoder.layers.3.norm1.bias\n",
      "  encoder.layers.3.norm2.weight\n",
      "  encoder.layers.3.norm2.bias\n",
      "  encoder.layers.4.self_attn.in_proj_weight\n",
      "  encoder.layers.4.self_attn.in_proj_bias\n",
      "  encoder.layers.4.self_attn.out_proj.weight\n",
      "  encoder.layers.4.self_attn.out_proj.bias\n",
      "  encoder.layers.4.linear1.weight\n",
      "  encoder.layers.4.linear1.bias\n",
      "  encoder.layers.4.linear2.weight\n",
      "  encoder.layers.4.linear2.bias\n",
      "  encoder.layers.4.norm1.weight\n",
      "  encoder.layers.4.norm1.bias\n",
      "  encoder.layers.4.norm2.weight\n",
      "  encoder.layers.4.norm2.bias\n",
      "  encoder.layers.5.self_attn.in_proj_weight\n",
      "  encoder.layers.5.self_attn.in_proj_bias\n",
      "  encoder.layers.5.self_attn.out_proj.weight\n",
      "  encoder.layers.5.self_attn.out_proj.bias\n",
      "  encoder.layers.5.linear1.weight\n",
      "  encoder.layers.5.linear1.bias\n",
      "  encoder.layers.5.linear2.weight\n",
      "  encoder.layers.5.linear2.bias\n",
      "  encoder.layers.5.norm1.weight\n",
      "  encoder.layers.5.norm1.bias\n",
      "  encoder.layers.5.norm2.weight\n",
      "  encoder.layers.5.norm2.bias\n",
      "  encoder.layers.6.self_attn.in_proj_weight\n",
      "  encoder.layers.6.self_attn.in_proj_bias\n",
      "  encoder.layers.6.self_attn.out_proj.weight\n",
      "  encoder.layers.6.self_attn.out_proj.bias\n",
      "  encoder.layers.6.linear1.weight\n",
      "  encoder.layers.6.linear1.bias\n",
      "  encoder.layers.6.linear2.weight\n",
      "  encoder.layers.6.linear2.bias\n",
      "  encoder.layers.6.norm1.weight\n",
      "  encoder.layers.6.norm1.bias\n",
      "  encoder.layers.6.norm2.weight\n",
      "  encoder.layers.6.norm2.bias\n",
      "  encoder.layers.7.self_attn.in_proj_weight\n",
      "  encoder.layers.7.self_attn.in_proj_bias\n",
      "  encoder.layers.7.self_attn.out_proj.weight\n",
      "  encoder.layers.7.self_attn.out_proj.bias\n",
      "  encoder.layers.7.linear1.weight\n",
      "  encoder.layers.7.linear1.bias\n",
      "  encoder.layers.7.linear2.weight\n",
      "  encoder.layers.7.linear2.bias\n",
      "  encoder.layers.7.norm1.weight\n",
      "  encoder.layers.7.norm1.bias\n",
      "  encoder.layers.7.norm2.weight\n",
      "  encoder.layers.7.norm2.bias\n",
      "  encoder.layers.8.self_attn.in_proj_weight\n",
      "  encoder.layers.8.self_attn.in_proj_bias\n",
      "  encoder.layers.8.self_attn.out_proj.weight\n",
      "  encoder.layers.8.self_attn.out_proj.bias\n",
      "  encoder.layers.8.linear1.weight\n",
      "  encoder.layers.8.linear1.bias\n",
      "  encoder.layers.8.linear2.weight\n",
      "  encoder.layers.8.linear2.bias\n",
      "  encoder.layers.8.norm1.weight\n",
      "  encoder.layers.8.norm1.bias\n",
      "  encoder.layers.8.norm2.weight\n",
      "  encoder.layers.8.norm2.bias\n",
      "  encoder.layers.9.self_attn.in_proj_weight\n",
      "  encoder.layers.9.self_attn.in_proj_bias\n",
      "  encoder.layers.9.self_attn.out_proj.weight\n",
      "  encoder.layers.9.self_attn.out_proj.bias\n",
      "  encoder.layers.9.linear1.weight\n",
      "  encoder.layers.9.linear1.bias\n",
      "  encoder.layers.9.linear2.weight\n",
      "  encoder.layers.9.linear2.bias\n",
      "  encoder.layers.9.norm1.weight\n",
      "  encoder.layers.9.norm1.bias\n",
      "  encoder.layers.9.norm2.weight\n",
      "  encoder.layers.9.norm2.bias\n",
      "  encoder.layers.10.self_attn.in_proj_weight\n",
      "  encoder.layers.10.self_attn.in_proj_bias\n",
      "  encoder.layers.10.self_attn.out_proj.weight\n",
      "  encoder.layers.10.self_attn.out_proj.bias\n",
      "  encoder.layers.10.linear1.weight\n",
      "  encoder.layers.10.linear1.bias\n",
      "  encoder.layers.10.linear2.weight\n",
      "  encoder.layers.10.linear2.bias\n",
      "  encoder.layers.10.norm1.weight\n",
      "  encoder.layers.10.norm1.bias\n",
      "  encoder.layers.10.norm2.weight\n",
      "  encoder.layers.10.norm2.bias\n",
      "  encoder.layers.11.self_attn.in_proj_weight\n",
      "  encoder.layers.11.self_attn.in_proj_bias\n",
      "  encoder.layers.11.self_attn.out_proj.weight\n",
      "  encoder.layers.11.self_attn.out_proj.bias\n",
      "  encoder.layers.11.linear1.weight\n",
      "  encoder.layers.11.linear1.bias\n",
      "  encoder.layers.11.linear2.weight\n",
      "  encoder.layers.11.linear2.bias\n",
      "  encoder.layers.11.norm1.weight\n",
      "  encoder.layers.11.norm1.bias\n",
      "  encoder.layers.11.norm2.weight\n",
      "  encoder.layers.11.norm2.bias\n",
      "  layernorm_embedding.weight\n",
      "  layernorm_embedding.bias\n",
      "  brain_projection.projection.weight\n",
      "  brain_projection.projection.bias\n",
      "  brain_projection.fc.weight\n",
      "  brain_projection.fc.bias\n",
      "Epoch 0/24\n",
      "lr: [5e-05]\n",
      "----------\n",
      "  8%| | 306/3609 [01:49<20:14,  2.72batch/s, loss=0.0392, lr=[0.0008048749999999^C\n",
      "  8%| | 306/3609 [01:49<19:42,  2.79batch/s, loss=0.0392, lr=[0.0008048749999999\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/working/EEG-to-Text-Decoding/train_decoding_raw.py\", line 431, in <module>\n",
      "    model = train_model(dataloaders, device, model, criterion, optimizer_step1, exp_lr_scheduler_step1, num_epochs=num_epochs_step1,\n",
      "  File \"/kaggle/working/EEG-to-Text-Decoding/train_decoding_raw.py\", line 153, in train_model\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py\", line 768, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash /kaggle/working/EEG-to-Text-Decoding/scripts/train_decoding_raw.sh"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5935890,
     "sourceId": 9705654,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5935908,
     "sourceId": 9705678,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5939946,
     "sourceId": 9711011,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5949567,
     "sourceId": 9723627,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5954865,
     "sourceId": 9730763,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5967925,
     "sourceId": 9748189,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5973288,
     "sourceId": 9755573,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5981995,
     "sourceId": 9767215,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 151757,
     "modelInstanceId": 128889,
     "sourceId": 151788,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 151758,
     "modelInstanceId": 128890,
     "sourceId": 151789,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 151759,
     "modelInstanceId": 128891,
     "sourceId": 151790,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 151764,
     "modelInstanceId": 128894,
     "sourceId": 151794,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
